Keywords,eigenvector,closeness,betweeness,clustering,pagerank,community
3d convolutional neural networks,0.039148955860637394,0.28725593429405216,0.0,0.0,0.001042723036427157,1
deep learning,0.6179141804605958,0.47752438109527384,0.4059629419659092,0.012452700378396972,0.114358482797277,1
abundance,2.235098264178812e-12,0.04759865603794716,0.0,1.0,0.0017622539848097302,2
bayesian analysis,1.1733689531079373e-11,0.06223083548664944,0.012710287128891778,0.08088235294117647,0.011810611532579899,2
hierarchical model,2.540757544865461e-12,0.04773387949260042,5.420935653493793e-06,0.6666666666666666,0.002624552149057977,2
abundance estimation,2.3868075448358406e-12,0.04786987345126879,0.0009107171897869572,0.3333333333333333,0.002745140110248638,2
hierarchical models,3.097725862102954e-12,0.04814419937362564,4.336748522795034e-05,0.5,0.002877741352838233,2
spatial point process,3.7969960954723463e-13,0.03862603581929965,0.0,0.0,0.001170033747561187,2
acoustic scene classification,0.010057621233780616,0.22429175475687105,0.0,0.0,0.0006532849396938119,1
convolutional neural networks,0.15875103802827278,0.32558480529223216,0.04351971004090428,0.0967741935483871,0.017549844480164622,1
acoustic simulation,0.003158111442168242,0.20967784439027604,0.0,1.0,0.0010740408871566388,4
reverberation,0.003158111442168242,0.20967784439027604,0.0,1.0,0.0010740408871566388,4
speech recognition,0.04669206413692587,0.2952777090549233,0.01978551164597676,0.1111111111111111,0.006066413379401656,4
acoustics,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
action recognition,0.049206577094418,0.29216952264381885,0.0,1.0,0.001231680257937892,1
active learning,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0006731370816500371,1
activity recognition,0.06182080427773497,0.298052130482285,0.0,1.0,0.0016264885955190383,1
machine learning,0.17947004444424433,0.34479633107034524,0.043068226956062446,0.11931818181818182,0.018916592060994625,1
transfer learning,0.1783877658905735,0.3431975845584271,0.046843172555896366,0.10476190476190476,0.017949095941362528,1
adversarial examples,0.0004535994294843125,0.17173150596233747,0.0,0.0,0.001005892947489081,1
robust speech recognition,0.007159570004702506,0.22543029158304803,0.004998102672521277,0.3333333333333333,0.003062132621900635,1
aerial image,0.04787490290096098,0.28875011340611484,0.0,1.0,0.0012842541081408963,1
drone,0.04787490290096098,0.28875011340611484,0.0,1.0,0.0014949913284760473,1
object detection,0.08986108979686996,0.30669728896312476,0.007728417661654559,0.2545454545454545,0.006353224539089302,1
alexnet,0.02491391467690608,0.24508701678730943,0.0008518010843592239,0.3333333333333333,0.0023623288721649066,1
convolutional neural network,0.2096725466914111,0.3410888436394813,0.06497264764784647,0.05782312925170068,0.031487360047293744,1
googlenet,0.005184778519131326,0.21453993933265927,1.3010245568385104e-05,0.0,0.001007688374719201,1
alzheimer's disease,0.05243274863659406,0.2952777090549233,0.0,1.0,0.001045866496252562,1
alzheimerâ€™s disease,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007011072479228109,1
ancillary augmentation,8.48172506831988e-13,0.013953488372093023,1.0841871306987584e-05,0.8,0.0031352128356378376,6
centered parameterization,8.48172506831988e-13,0.013953488372093023,1.0841871306987584e-05,0.8,0.0031352128356378376,6
non-centered parameterization,4.804111440948026e-13,0.009302325581395349,0.0,1.0,0.0023668805788418764,6
reparameterization,7.718748836608642e-13,0.011960132890365448,0.0,1.0,0.001489593406062972,6
state-space model,7.718748836608642e-13,0.011960132890365448,0.0,1.0,0.001489593406062972,6
sufficient augmentation,8.48172506831988e-13,0.013953488372093023,1.0841871306987584e-05,0.8,0.0031352128356378376,6
time series,7.718748836608642e-13,0.011960132890365448,0.0,1.0,0.001489593406062972,6
anomaly detection,0.0034718354405020384,0.2084965607599083,0.0,0.0,0.0008239626048802924,1
neural network,0.05480231599693243,0.2933273939356702,0.0033808568692289625,0.3333333333333333,0.0028263814824826517,1
apache spark,0.0026088442227163626,0.2084965607599083,0.0,0.0,0.0006731519328949925,5
big data,0.04118078391293872,0.2933273939356702,0.02618311920637502,0.5833333333333334,0.004126556074576403,5
artificial intelligence,0.06574767025742098,0.29845273818454615,3.1441426790264004e-05,0.8333333333333334,0.002306500912202268,1
deep neural network,0.061984517193167346,0.29606511627906973,1.2106756292802804e-05,0.8333333333333334,0.002281854692476849,1
artificial neural network,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0010578523726631705,1
artificial neural networks,0.011416034739334198,0.2337356181150551,0.0033392963625521765,0.0,0.0015929740346386594,1
expert knowledge,0.000723250387981542,0.17650940954634525,0.0,0.0,0.0005201017521718713,1
asymptotic normal data augmentation,3.607793845977818e-12,0.04628739829585495,0.0009107171897869572,0.0,0.0019620168845502998,2
cure model,5.243353180943793e-13,0.03758909526039228,0.0,0.0,0.0011908626130411565,2
multiple imputation,2.4352334917206122e-11,0.05979475295870231,0.003252561392096278,0.0,0.004027413056103709,2
atr,0.0024901189997088135,0.2057913227148307,0.0,0.0,0.0010689086153098917,1
sar,0.039306725753532,0.2880010858745815,0.0033392963625521765,0.0,0.001381930403886584,1
atrial fibrillation,0.0008449617993205824,0.17553267763581212,0.0,0.0,0.001507869496912882,1
electrocardiogram,0.013337325750362193,0.23202595319676317,0.0033392963625521765,0.0,0.0017419447143895463,1
attributed scattering center (asc),0.0004701584535311304,0.1647246566834587,0.0,0.0,0.0011398321375611351,1
synthetic aperture radar (sar),0.007420845806004698,0.21350849731663685,0.00335646265878824,0.0,0.0026440914596258048,1
augmentation,0.00420873228042607,0.20967784439027604,0.0,1.0,0.002383573757769266,5
cmm,0.00420873228042607,0.20967784439027604,0.0,1.0,0.0023835737577692665,5
data lake,0.00420873228042607,0.20967784439027604,0.0,1.0,0.0023835737577692665,5
data warehouse,0.00420873228042607,0.20967784439027604,0.0,1.0,0.0023835737577692665,5
dm,0.00420873228042607,0.20967784439027604,0.0,1.0,0.0023835737577692665,5
map reduce,0.00420873228042607,0.20967784439027604,0.0,1.0,0.0023835737577692665,5
olap,0.00420873228042607,0.20967784439027604,0.0,1.0,0.0023835737577692665,5
augmented reality,0.01137021355246156,0.23324457690052766,0.0,0.0,0.0007523169000874314,1
autoencoder,0.00042120692462682756,0.17133397932816538,0.0,0.0,0.0007749264446141065,1
unsupervised learning,0.006648265916390511,0.22474578664909142,0.0033392963625521765,0.0,0.0016035543418497456,1
automatic speech recognition,0.0037591007346247794,0.21147508305647839,6.595471711750782e-05,0.3333333333333333,0.003261597810091962,4
deep neural networks,0.05255753047529028,0.2976525967953114,0.021089821352896162,0.13333333333333333,0.006940786598042047,4
end-to-end,0.0031961842176410687,0.2102735200845666,3.252561392096276e-05,0.0,0.001602825299189398,4
stochastic feature mapping,0.0035821855125259205,0.21147508305647839,0.0033392963625521765,0.3333333333333333,0.003535435359306777,4
autonomous driving,0.00569298053951281,0.21516360194699835,0.0,0.0,0.0011374742647787912,1
autonomous vehicle,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0006108657920210437,1
auxiliary variables,2.755037669262877e-12,0.04842168755445345,0.0,0.0,0.0008324759784847627,2
mcmc,1.8637100414703397e-11,0.06388716951100892,0.004688140142685602,0.05555555555555555,0.005650275352411003,2
background subtraction,0.011516896844593104,0.22474578664909142,0.0,1.0,0.0010756975490745307,1
illumination-invariant,0.011516896844593104,0.22474578664909142,0.0,1.0,0.0010756975490745307,1
synthetics,0.011516896844593104,0.22474578664909142,0.0,1.0,0.0010756975490745307,1
batch normalization,0.05921372600766924,0.29606511627906973,0.00011022569162104045,0.6666666666666666,0.0023241413201691564,1
convolution neural network,0.04290027260537308,0.28762802747318955,0.0,1.0,0.0016672981045051452,1
dropout,0.06413612583545837,0.297254132810311,0.0012114383150323956,0.4,0.004343415999223591,1
bayes factors,3.1188684131295716e-12,0.054026770358184394,0.0,0.0,0.0009958405150941115,2
markov chain monte carlo,2.079593043632176e-11,0.07401905542464912,0.012259492914884046,0.07575757575757576,0.009941239303711475,2
bayesian,5.873906082392448e-12,0.057150767283657644,0.000277645774474527,0.0,0.0013040541206565408,2
camera trapping,2.235098264178812e-12,0.04759865603794716,0.0,1.0,0.0018510432229383574,2
capture-recapture,2.2706527993217788e-12,0.04773387949260042,0.0,1.0,0.0015876692612524718,2
count data,4.4282927702456376e-12,0.0558216796724098,0.0009107171897869572,0.3333333333333333,0.00194573332278309,2
density estimation,3.0132922093520176e-12,0.04786987345126879,1.626280696048138e-05,0.5,0.0032028769485946272,2
distance sampling,2.3116483020714876e-12,0.04759865603794716,0.0,1.0,0.001752273592626959,2
gibbs sampling,1.6620034094757504e-11,0.07119629483642097,0.006152895730062748,0.26666666666666666,0.00398357184896925,2
heterogeneity,1.8312139473984936e-12,0.047464196557613976,0.0,0.0,0.0008847057280261858,2
misclassification,2.651938008148424e-12,0.054553005134400485,0.0003686236244375779,0.0,0.0008065925781228292,2
population size,2.757273393165598e-12,0.04800664451827242,0.0009161381254404509,0.3333333333333333,0.0029993374411145346,2
spatial capture-recapture,2.8059698011869524e-12,0.04773387949260042,5.420935653493793e-06,0.6666666666666666,0.0021718457600648205,2
spatially explicit capture-recapture,1.8312139473984936e-12,0.047464196557613976,0.0,0.0,0.0009498155297903,2
trapping grid,2.3116483020714876e-12,0.04759865603794716,0.0,1.0,0.0018888680138662696,2
bayesian data augmentation,2.055979702507223e-11,0.05545321974057871,0.0,0.0,0.0009381280796716845,2
missing data,1.4243597732939748e-10,0.07672294786025273,0.020631966107653214,0.10909090909090909,0.007571753634807128,2
bayesian estimation,5.7866672341246e-12,0.05619506883409815,0.0004247338285393253,0.3333333333333333,0.0017032715458445533,2
start-up demonstration test,3.622927328454091e-12,0.051383258658701365,0.0,1.0,0.001412305433391748,2
bayesian inference,3.416099121303741e-11,0.0774300718036652,0.011502000466059674,0.06666666666666667,0.0075877289059259,2
fiducial inference,5.007650558404811e-12,0.0558216796724098,0.0,0.0,0.0007197965846267656,2
hidden markov model,5.87352524567251e-12,0.05600775193798449,0.0,1.0,0.0016613238778687175,2
markov chain monte carlo methods,5.542025664592459e-12,0.05979475295870231,0.0013769176559874233,0.0,0.0028543450528367717,2
mcmc methods,5.007650558404811e-12,0.0558216796724098,0.0,0.0,0.0009629983833553929,2
switching diffusion,5.87352524567251e-12,0.05600775193798449,0.0,1.0,0.0016613238778687173,2
variable splitting,8.126518971534383e-12,0.06316663752404267,0.0,1.0,0.0013156742583922722,2
bayesian methods,3.807087904400686e-11,0.05676461345065996,0.0018105925082669268,0.4,0.003853103369453059,2
biological monitoring,3.6677353313956466e-11,0.05638364289058841,0.0,1.0,0.0020426909749601168,2
ecological health,3.6677353313956466e-11,0.05638364289058841,0.0,1.0,0.0020426909749601168,2
generalized linear models,5.507321080098379e-12,0.04421664626682986,0.0,0.0,0.0008027214842405579,2
logistic models,5.507321080098379e-12,0.04421664626682986,0.0,0.0,0.0013505636633970636,2
stressor-response,3.6677353313956466e-11,0.05638364289058841,0.0,1.0,0.0020426909749601168,2
bayesian optimization,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0011706145881951102,1
binary data,3.1188684131295716e-12,0.054026770358184394,0.0,0.0,0.0010203844338047448,2
biometric,0.015891509780554897,0.2334898393368058,0.0,1.0,0.001200850274526906,1
face recognition,0.05655812612292224,0.2956708884278327,0.0019329507701600708,0.5,0.002275009745584661,1
inception-resnet-v2,0.015891509780554897,0.2334898393368058,0.0,1.0,0.0012008502745269058,1
brain,0.04864823705874108,0.2880010858745815,0.0,1.0,0.0017443467748248494,1
mri,0.08880191874338512,0.3096915442249684,0.0011864053723083887,0.4444444444444444,0.006288658648666298,1
multiple sclerosis,0.06114060100978269,0.29606511627906973,6.993006993006996e-05,0.8333333333333334,0.0025407602690340455,1
brain tumor,0.06497514202008381,0.2968567342370352,0.0,1.0,0.003631067035278602,1
segmentation,0.10917306805645059,0.3136283011430824,0.008397776065546049,0.25274725274725274,0.008372666808394501,1
brain-computer interface,0.0024901189997088135,0.2057913227148307,0.0,0.0,0.0010543546856332407,1
electroencephalography,0.039306725753532,0.2880010858745815,0.0033392963625521765,0.0,0.001734596244540028,1
breast cancer,0.08148032468429837,0.30926021895446004,0.0008986075515506913,0.5333333333333333,0.0034452335077805804,1
computer-aided detection,0.044310942958612556,0.28762802747318955,0.0,1.0,0.0010343981339687469,1
convolutional neural network (cnn),0.07704664698161708,0.30169678968655206,0.010896874227240274,0.15151515151515152,0.0075075069558740975,1
cameras,0.00031422038954403384,0.16657827247509552,0.0,0.0,0.001388125279102889,1
training,0.004959573421135999,0.21663301191151446,0.0033392963625521765,0.3333333333333333,0.002489633183745123,1
cardiac mri,0.046065457344038475,0.2883751132588342,0.0,1.0,0.000956360053915004,1
categorization,0.04482894216218635,0.2880010858745815,0.0,1.0,0.0030429825894619776,1
recognition: detection,0.04482894216218635,0.2880010858745815,0.0,1.0,0.003042982589461978,1
retrieval,0.04482894216218635,0.2880010858745815,0.0,1.0,0.0030448705865787264,1
character animation,0.04482894216218635,0.2880010858745815,0.0,1.0,0.0022612890312736006,1
interactive motion control,0.04482894216218635,0.2880010858745815,0.0,1.0,0.002157224592726014,1
motion grammar,0.04482894216218635,0.2880010858745815,0.0,1.0,0.002157224592726014,1
chest x-ray,0.06500520584654333,0.297254132810311,0.0006510309330471362,0.8,0.00287678258341552,1
computer-aided diagnosis,0.06759269416782272,0.2976525967953114,0.0007838438565577365,0.6,0.003945227668839211,1
tuberculosis,0.02168418552950342,0.23226865816872627,0.0,1.0,0.0017980973527619026,1
chord recognition,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,14
robot,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,14
class imbalance,0.05243274863659406,0.2952777090549233,0.0,1.0,0.0009630315010459923,1
classification,0.12892700982657912,0.326062903391046,0.01170281113745957,0.2833333333333333,0.008270154134790497,1
cnn,0.1178359003807127,0.3185779586934036,0.032435060553886674,0.11594202898550725,0.012579785320294875,1
computer vision,0.09333019705086504,0.3136283011430824,0.00024585715583823965,0.9333333333333333,0.00355086918721788,1
convolutional network,0.008167978763392774,0.22451854116208528,0.0,0.0,0.0007263664424440536,1
gan,0.07130634775688267,0.3041764893278114,0.01674918574495742,0.25,0.0047705687188892894,1
generalization,0.014789560417067086,0.2315420617406698,5.885587280936116e-05,0.0,0.0010181257046993247,1
image processing,0.09556618681957309,0.31012407431466804,0.0007922874697104139,0.6071428571428571,0.00382841048815007,1
melanoma,0.056925919537933065,0.29063983927919157,0.0024824357382496926,0.5,0.0021643710703116853,1
neural networks,0.06462158381696842,0.29606511627906973,0.0052778745802001615,0.3333333333333333,0.004301616867536962,1
pre-processing,0.008167978763392774,0.22451854116208528,0.0,0.0,0.0005758103765928632,1
skin cancer,0.05092332888569788,0.2895030472089991,0.0,1.0,0.001727054507830491,1
cnn-blstm,0.021489935878790223,0.2403125943823618,0.0,1.0,0.0010293083713139137,1
covid-19,0.04661429847904364,0.2925544627263535,0.0,1.0,0.0013907988091869904,1
deep-learning,0.007495427313851505,0.22138468315982285,0.0033392963625521765,0.0,0.00168200413685643,1
feature extraction,0.026208445833558826,0.24400971121901355,0.0008643821694245962,0.16666666666666666,0.002406244707578467,1
handwriting,0.021489935878790223,0.2403125943823618,0.0,1.0,0.0010293083713139137,1
image classification,0.09321265087862324,0.31676011014165806,0.002833368202697555,0.5714285714285714,0.0044756681781581605,1
image segmentation,0.07303025787756962,0.3084011627906977,0.011258785354525454,0.3333333333333333,0.0029904820532352327,1
knowledge distillation,0.007465342618406249,0.22094411662617147,0.0,0.0,0.0010315387976898797,1
lstm,0.05111071635359805,0.2976525967953114,0.008208102472497448,0.2,0.004497240272512993,1
motor imagery,0.007465342618406249,0.22094411662617147,0.0,0.0,0.0009646225315362449,1
nlp,0.007465342618406249,0.22094411662617147,0.0,0.0,0.0007785855009149812,1
overfitting,0.053371827571158555,0.2937153931339978,0.00013687275843724046,0.5,0.002763288128528266,1
parkinsonâ€™s disease (pd),0.021489935878790223,0.2403125943823618,0.0,1.0,0.0010293083713139137,1
resnet,0.019523452799128625,0.24005279698302953,0.00017756228488724442,0.6666666666666666,0.0019361274640422575,1
svm,0.009125754036473172,0.22634947727757626,0.0,1.0,0.0008830503699327374,1
vgg,0.011940197394594131,0.22338917224275887,3.5236081747709655e-05,0.6666666666666666,0.0020646507244386257,1
x-ray,0.007465342618406249,0.22094411662617147,0.0,0.0,0.0004724869170557466,1
collaborative filtering,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,15
data sparsity,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,15
compact operator,9.84518534519668e-11,0.04814419937362564,0.0,0.0,0.0006387769933618266,3
data augmentation algorithm,6.84331603397955e-10,0.06340500219394471,0.014481126109033087,0.21323529411764705,0.008329492232878063,3
computational pathology,0.049206577094418,0.29216952264381885,0.0,1.0,0.0015971023678715587,1
computed tomography,0.04343112156805495,0.2880010858745815,0.0,1.0,0.0016397796513296888,1
computer aided diagnosis,0.05105316935699439,0.28875011340611484,1.0841871306987586e-05,0.7,0.0022959243151333113,1
convolutional neural networks.,0.05105316935699439,0.28875011340611484,1.0841871306987586e-05,0.7,0.0022334433261728113,1
parkinson',0.04561763793496427,0.2880010858745815,0.0,1.0,0.001229256567868394,1
parkinson's disease,0.04561763793496427,0.2880010858745815,0.0,1.0,0.0012697452782649344,1
s disease,0.04561763793496427,0.2880010858745815,0.0,1.0,0.001229256567868394,1
conditional generative adversarial networks,0.0009054866735602222,0.17186442508459934,0.0,1.0,0.001480381558106731,1
very deep convolutional neural network,0.007132545665323906,0.22520166045568188,0.0016588063099691006,0.6666666666666666,0.002225933729563377,1
conditional model,0.007368658222800174,0.22006822320049785,0.0,0.0,0.0007270384954242638,1
generative adversarial network,0.1163099834516192,0.31676011014165806,0.01205563549588878,0.20588235294117646,0.009763605519506297,1
conditional variational auto-encoder,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007467074772156115,1
convergence rate,1.8149099052685804e-10,0.04856163462831025,0.0,1.0,0.001068558385870052,3
markov chain,5.772693622191506e-10,0.05030636401615374,0.002009360148895032,0.28205128205128205,0.006369267195456425,3
convolution neural networks,0.039148955860637394,0.28725593429405216,0.0,0.0,0.000882287229987528,1
convolutional networks,0.0007398389541589269,0.1721308815575987,0.0,1.0,0.002244429664036495,7
liveness,0.0007398389541589269,0.1721308815575987,0.0,1.0,0.002244429664036495,7
local binary patterns,0.0007398389541589269,0.1721308815575987,0.0,1.0,0.002244429664036495,7
support vector machines,0.010198238335548823,0.22565938740782757,0.009952837859814604,0.5,0.0026476598140470044,7
data preprocessing,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0007902806046961962,1
diabetic retinopathy,0.05243274863659406,0.2952777090549233,0.0,1.0,0.0016662098795487109,1
facial expression recognition,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0006658152076852095,1
feature representation,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0012165321474507389,1
fine-tuning,0.06373438350123008,0.3012874317629611,0.0,1.0,0.0017175793834516113,1
fish classification,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0007068574675776831,1
generative adversarial networks,0.10451907381518036,0.32558480529223216,0.0341096693743327,0.14166666666666666,0.010734934119239915,1
graph convolutional network,0.013283792775956678,0.2315420617406698,0.0,0.0,0.00083726207911745,1
image enhancement,0.013283792775956678,0.2315420617406698,0.0,0.0,0.000766910748632986,1
image preprocessing,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0007790133512334126,1
leaky rectified linear unit,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0011987911113866623,1
loss function,0.017910425604195108,0.23447606885881975,0.0,1.0,0.0012097647516716517,1
max pooling,0.05243274863659406,0.2952777090549233,0.0,1.0,0.0017036439296253486,1
parametric rectified linear unit,0.017346974136914148,0.23251187142335322,0.0,1.0,0.0018608980222364708,1
person re-identification,0.05980140685939424,0.2976525967953114,0.0,1.0,0.0015870844341927981,1
raw waveform,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0005274426549025307,1
remote sensing,0.08148773727854836,0.31012407431466804,0.003671286162662596,0.5333333333333333,0.0028366530701612667,1
stochastic pooling,0.013283792775956678,0.2315420617406698,0.0,0.0,0.0011607802220619373,1
style transfer,0.05243274863659406,0.2952777090549233,0.0,1.0,0.0015603562581327762,1
support vector machine,0.06380296218905562,0.30006599622878694,0.0,1.0,0.0018353486521703007,1
synthetic aperture radar,0.05243274863659406,0.2952777090549233,0.0,1.0,0.0009160500266247385,1
traffic sign detection,0.013283792775956678,0.2315420617406698,0.0,0.0,0.000990135860354333,1
data normalization,0.044518041257480614,0.2898809885238934,0.001263889974249383,0.6666666666666666,0.0016297642704271673,1
generative adversarial network (gan),0.044207547428528324,0.29025991792065664,0.0033392963625521765,0.3333333333333333,0.002148019244631981,1
internet of things (iot),0.007701434503657422,0.21289437891591784,0.0,1.0,0.0011317438775825315,1
micro-expression recognition,0.04719836840404438,0.29063983927919157,0.0033392963625521765,0.5,0.0028131591973426366,1
small training data,0.047020209972035466,0.29025991792065664,0.0,1.0,0.002212389415075505,1
target recognition,0.004881151117646008,0.21269045709703288,0.0,0.0,0.001324636238268821,1
document image classification,0.056345839006779454,0.2929404184819292,0.0,1.0,0.0026604726029566803,1
fine tuning,0.010057621233780616,0.22429175475687105,0.0,0.0,0.00046611740731053615,1
hep-2 cells,0.010057621233780616,0.22429175475687105,0.0,0.0,0.0008307145514441997,1
intelligent surveillance systems,0.06057679064687956,0.2968567342370352,0.0,1.0,0.0013607101977769502,1
mitosis detection,0.010057621233780616,0.22429175475687105,0.0,0.0,0.0010789815323265692,1
multiclass classification,0.05253475105304884,0.2925544627263535,0.0,1.0,0.0012521291085326324,1
network architecture,0.056345839006779454,0.2929404184819292,0.0,1.0,0.0026604726029566803,1
object classification,0.010057621233780616,0.22429175475687105,0.0,0.0,0.00046611740731053615,1
pattern recognition,0.06689971422662962,0.298052130482285,0.0033392963625521765,0.6,0.002751033676243167,1
preprocessing,0.056345839006779454,0.2929404184819292,0.0,1.0,0.002842932117260829,1
principal component analysis,0.05253475105304884,0.2925544627263535,0.0,1.0,0.0014779840991893092,1
semantic segmentation,0.06818286365390855,0.297254132810311,0.0014021662089736292,0.6,0.0033092980253033805,1
skin lesion classification,0.049206577094418,0.29216952264381885,0.0,1.0,0.0013497698230210498,1
traffic sign recognition,0.049206577094418,0.29216952264381885,0.0,1.0,0.0007176562511676207,1
convolutional neural networks (cnns),0.03961911431416852,0.28875011340611484,0.0025205520342941067,0.0,0.001751678175564989,1
poisson distribution,6.830138497597643e-13,0.043642404107520384,0.0,0.0,0.0006363512473094636,2
crack detection,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
crowdsourcing,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007831185571047124,1
ct,0.004294074434689317,0.21087258994235736,0.0,0.0,0.0007565170271965993,1
image synthesis,0.06778021932168632,0.298052130482285,0.004781870310411553,0.32142857142857145,0.00685630232881385,1
drift condition,3.0172328873242527e-10,0.049273682056877856,0.0009251730181962741,0.5333333333333333,0.0026428744612354907,3
eigenvalues,2.420805479647806e-10,0.048702392989551736,0.0,1.0,0.0013610250519951004,3
geometric convergence rate,3.940838211990202e-10,0.04912960696314429,1.0841871306987586e-05,0.8666666666666667,0.002656703947835585,3
geometric ergodicity,2.9626490649362633e-10,0.04912960696314429,1.445582840931678e-05,0.8,0.002629407287661039,3
haar px-da algorithm,2.2861358896053617e-10,0.04884396971335857,3.252561392096276e-05,0.6,0.0017021908285531646,3
heavy-tailed distribution,1.5340943094774098e-10,0.04842168755445345,0.0,1.0,0.0012602779669795019,3
markov operator,3.940838211990202e-10,0.04912960696314429,1.0841871306987586e-05,0.8666666666666667,0.002688790861157805,3
minorization condition,2.6751318051847825e-10,0.048986371957420845,0.0,1.0,0.002502447410704862,3
monte carlo,4.2120360776959837e-10,0.049273682056877856,2.5297699716304366e-05,0.6666666666666666,0.003353417664877939,3
polya-gamma distribution,2.420805479647806e-10,0.048702392989551736,0.0,1.0,0.0017542791137306077,3
sandwich algorithm,2.685170899027879e-10,0.04856163462831025,0.0,1.0,0.0018195052381983893,3
scale mixture,1.5340943094774098e-10,0.04842168755445345,0.0,1.0,0.0012602779669795019,3
trace-class operator,3.940838211990202e-10,0.04912960696314429,1.0841871306987586e-05,0.8666666666666667,0.0026887908611578047,3
data augmentation.,0.039148955860637394,0.28725593429405216,0.0,0.0,0.001061445498419947,1
data simulation,0.0032379613114201407,0.21067252107144432,0.0,0.0,0.00048431943722749285,1
data-augmentation,0.0004748710943488011,0.1693736363152573,0.0,0.0,0.001276384296152927,1
deep cnn,0.012066068782989879,0.2327555945590171,0.0,1.0,0.0013023058526816789,1
fall detection,0.012066068782989879,0.2327555945590171,0.0,1.0,0.0013893833229195486,1
deep convolutional neural network,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0009004470654169276,1
deep convolutional neural network (dcnn),0.002800612828661096,0.20694206636468063,0.0,0.0,0.0012951007810766977,1
deep convolutional neural networks,0.0504505907252734,0.2933273939356702,0.0,1.0,0.0008245023620436791,1
deep leaning,0.011301634864636013,0.23251187142335322,0.0,0.0,0.0005867386816650036,1
defect detection,0.05315492248683628,0.2941044201447713,0.000148172241195497,0.6666666666666666,0.0021951900251212047,1
detection,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0005473676597214949,1
detection of pelagic fish,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
domain adaptation,0.07049210976654728,0.3021072615092549,0.004618066412810656,0.47619047619047616,0.003418404131362806,1
drum transcription,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008621056809258304,1
elderly people,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007011072479228109,1
electroencephalogram,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0010541866536182437,1
emotion recognition,0.039306725753532,0.2880010858745815,0.0033392963625521765,0.0,0.002144284254538282,1
ensemble,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0005995666860844628,1
ensemble learning,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0005473676597214949,1
environmental monitoring,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
environmental sound classification,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0014788863470661777,1
face detection,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008511055299415474,1
fashion-mnist,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0005473676597214949,1
faster r-cnn,0.04268776472752177,0.2883751132588342,0.0033392963625521765,0.3333333333333333,0.0024965333469408155,1
fully convolutional network,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007831185571047124,1
fully convolutional neural network,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0009088879790332548,1
generative model,0.039148955860637394,0.28725593429405216,0.0,0.0,0.001276672062783136,1
generative models,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0012446736460335205,1
hand gesture recognition,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008724768991441536,1
human activity recognition,0.039148955860637394,0.28725593429405216,0.0,0.0,0.001064968850316486,1
hyperspectral imaging,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008621056809258304,1
instance segmentation,0.039148955860637394,0.28725593429405216,0.0,0.0,0.000725336108013005,1
internet of things,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008724768991441536,1
iris recognition,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008511055299415474,1
keras,0.0504505907252734,0.2933273939356702,0.0,1.0,0.0011953966256195764,1
lesion classification,0.05175833110277885,0.29063983927919157,0.0006961478737377264,0.8333333333333334,0.004094245989574699,1
long-short term memory networks,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
mammogram,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0006731370816500371,1
mammography,0.039148955860637394,0.28725593429405216,0.0,0.0,0.000882287229987528,1
medical image,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0010032177805862302,1
medical image analysis,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0006400553964810032,1
medical image segmentation,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008511055299415474,1
medical image synthesis,0.04651761408343756,0.2895030472089991,0.0,1.0,0.0010248747025311973,1
medical imaging,0.050519169413098954,0.2917855942303578,0.0,1.0,0.002351207070491681,1
microscopic object detection,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007658248184095457,1
monitoring,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0005473676597214949,1
multi-label classification,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0010466252711536003,1
multi-task learning,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0006731370816500371,1
object recognition,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0005473676597214949,1
periocular recognition,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0011082277965273712,1
person identification,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007658248184095457,1
principle component analysis,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007011072479228109,1
real-time systems,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
recurrent neural network,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008393952139751199,1
recurrent neural networks,0.039306725753532,0.2880010858745815,0.0033392963625521765,0.0,0.0023249988901663087,1
recycling,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008511055299415474,1
residual network,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007831185571047124,1
retina,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008268766698513532,1
review,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0012799026571079979,1
scene classification,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008915942403380878,1
semi-supervised learning,0.048120669339727355,0.2937153931339978,0.0001590141125024846,0.6666666666666666,0.002283472220930871,4
sentiment analysis,0.04236755789086285,0.2883751132588342,0.0033392963625521765,0.3333333333333333,0.002134155482902145,4
signal detection,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
signal processing,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0006400553964810032,1
small dataset,0.04247860246147925,0.29025991792065664,0.0,1.0,0.000952395363960537,4
sonar,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
spectral ct,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0006731370816500371,1
stock market index,0.0425301819004013,0.28762802747318955,0.0,1.0,0.0017936750583987403,1
supervised learning,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0009391994283879437,1
synthetic data,0.050519169413098954,0.2917855942303578,0.0,1.0,0.0010939084464838397,1
target detection,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0007831185571047124,1
tensorflow,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0010218440608002976,1
time-series data augmentation,0.039148955860637394,0.28725593429405216,0.0,0.0,0.001068425086650465,1
traffic congestion,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0008134300064594013,1
training data augmentation,0.039487385223277584,0.28875011340611484,0.006656908982490378,0.3333333333333333,0.0025387766905393926,13
transceivers,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
tumor segmentation,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0012255563048395863,1
u-net,0.046065457344038475,0.2883751132588342,0.0,1.0,0.001106548152913452,1
uav,0.039148955860637394,0.28725593429405216,0.0,0.0,0.001087884457957574,1
uncertainty,0.039148955860637394,0.28725593429405216,0.0,0.0,0.0009590133037244176,1
underwater acoustics,0.039148955860637394,0.28725593429405216,0.0,0.0,0.00047379726415592053,1
yolov3,0.044841936400150204,0.2883751132588342,0.0,1.0,0.000910271761014454,1
iris segmentation,0.0033296466008418566,0.21067252107144432,0.0,0.0,0.001210782862643587,4
regularization,0.009234909539916663,0.22588894934822212,3.7946549574456546e-05,0.0,0.000793930251490989,4
text classification,0.003343064681458055,0.2110730391723406,0.0033392963625521765,0.0,0.0015704603144672462,4
diabetes,3.3243774919574067e-21,0.004651162790697674,0.0,1.0,0.0022564193143721663,10
grammatical evolution,3.3243774919574067e-21,0.004651162790697674,0.0,1.0,0.0023520687650877004,10
time series forecasting,3.3243774919574067e-21,0.004651162790697674,0.0,1.0,0.0023520687650877004,10
distributed artificial intelligence,0.01213928512731574,0.2334898393368058,0.0,1.0,0.0008085212275698799,1
wireless communication,0.01213928512731574,0.2334898393368058,0.0,1.0,0.0008085212275698799,1
image-to-image translation,0.022867444183739878,0.22938929463770902,0.0034176300561078576,0.4,0.002576675473847857,1
maximum mean discrepancy,0.004465864622393852,0.21289437891591784,0.0,0.0,0.0005937341749557555,1
posterior propriety,4.3403670511938694e-11,0.03953488372093023,0.0,0.0,0.0005612675065648654,3
eeg,0.0024901189997088135,0.2057913227148307,0.0,0.0,0.001202069129942157,1
eeg (electroencephalogram),3.3243774919574067e-21,0.004651162790697674,0.0,1.0,0.002320185614849188,11
long short term memory (lstm),3.3243774919574067e-21,0.004651162790697674,0.0,1.0,0.002320185614849188,11
recurrent neural network (rnn),3.3243774919574067e-21,0.004651162790697674,0.0,1.0,0.002320185614849188,11
em algorithm,3.484826937374419e-11,0.0774300718036652,0.011341179375006017,0.08888888888888889,0.006683076103779512,2
gibbs sampler,1.2590472137420421e-11,0.06694153618085795,0.0031471277137239094,0.2,0.0051206291361788545,2
ibf sampler,6.987343343861612e-12,0.05657348680604494,0.0,1.0,0.001628911231933351,2
incomplete data,5.111397666873649e-12,0.0558216796724098,0.0,0.0,0.0009593855695270504,2
infectious disease,5.111397666873649e-12,0.0558216796724098,0.0,0.0,0.0009208217784524996,2
interval censoring,5.111397666873649e-12,0.0558216796724098,0.0,0.0,0.000855219278856861,2
small sample,5.111397666873649e-12,0.0558216796724098,0.0,0.0,0.0006884485170722741,2
epidemics,8.207240607499299e-13,0.046033768716151634,0.0,0.0,0.0013722667662725296,2
ergm,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,16
multilevel networks,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,16
underwater-imaging,0.002704331761562875,0.20598222375631015,0.0,0.0,0.001055704444475182,1
fault diagnosis,0.00028852430927892643,0.1657080874696286,0.0033392963625521765,0.0,0.002384008087716969,12
imbalanced data,0.00453572122115339,0.21474742476721695,0.006656908982490378,0.0,0.0017904812535496368,12
rolling bearing,1.827843940659371e-05,0.13473837209302325,0.0,0.0,0.0014996448353281743,12
vae,0.004517442781746796,0.21391988170453016,0.0,0.0,0.0006512077336670345,1
weather classification,0.004517442781746796,0.21391988170453016,0.0,0.0,0.0006091727864719704,1
gans,0.001448783174783705,0.17401946489757236,0.0,0.0,0.0006477024900759645,1
liver lesions,0.014941724348955665,0.22474578664909142,0.0,1.0,0.0030742972524626907,1
vehicle detection,0.007368658222800174,0.22006822320049785,0.0,0.0,0.0007137670758193407,1
image translation,0.006621581653674314,0.22429175475687105,0.0,0.0,0.0009117349144594556,1
physician training,0.006621581653674314,0.22429175475687105,0.0,0.0,0.0010691428836397702,1
speech emotion recognition,0.006621581653674314,0.22429175475687105,0.0,0.0,0.0008709376715031505,1
marginal data augmentation,1.9196847478968703e-12,0.050457434178364416,0.0009107171897869572,0.0,0.0025722072271989233,2
metropolis-hastings algorithm,1.875945676987962e-12,0.05015619576535925,0.0,0.0,0.001018048715757728,2
grouping and shape,0.006916501483401093,0.21855200512726608,0.0,0.0,0.0009532202325416375,1
heavy-tailedness,5.908290695050735e-13,0.043082886106141915,0.0,1.0,0.0018205982794574876,2
parameter expansion,3.300238392023406e-12,0.054730702219528825,0.0017997506369599391,0.3333333333333333,0.00243043551420382,2
sample selection,5.908290695050735e-13,0.043082886106141915,0.0,1.0,0.0018205982794574874,2
host phenotypes,0.016510139665900335,0.2342287312334413,0.0,1.0,0.0018152819184549759,1
metagenomics,0.016510139665900335,0.2342287312334413,0.0,1.0,0.0018152819184549757,1
human tracking,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,17
multi-domain network,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,17
image augmentation,0.011301634864636013,0.23251187142335322,0.0,0.0,0.0007263755712516834,1
image registration,0.006916501483401093,0.21855200512726608,0.0,0.0,0.0006953425829692857,1
task analysis,0.004940853217782464,0.216421868625051,0.0,1.0,0.0012950367703543735,1
imu,0.01137021355246156,0.23324457690052766,0.0,0.0,0.0008257122376131201,1
inception-v3,0.011301634864636013,0.23251187142335322,0.0,0.0,0.000775912546177156,1
incompatible gibbs sampler,2.8842596155277496e-13,0.04029334671797446,0.0,0.0,0.001460825963970207,2
individual covariates,4.394388519232853e-13,0.0387150359018326,0.0,0.0,0.0009483339631342101,2
language modeling,0.00295802316846914,0.2094800351031154,0.0,0.0,0.0009128845150065011,4
lighthouse probe,5.890029704620749e-18,0.0069767441860465115,0.0,1.0,0.002320185614849188,8
multivariate curve resolution,5.890029704620749e-18,0.0069767441860465115,0.0,1.0,0.002320185614849188,8
process analytical technology,5.890029704620749e-18,0.0069767441860465115,0.0,1.0,0.002320185614849188,8
simplisma,5.890029704620749e-18,0.0069767441860465115,0.0,1.0,0.002320185614849188,8
lithography hotspot detection,0.01137021355246156,0.23324457690052766,0.0,0.0,0.000942577983905659,1
local binary pattern-three orthogonal planes (lbp-top),0.0029901029937520742,0.20713510933703577,0.0,0.0,0.0007496685118680947,1
locomotion,0.004093933994764385,0.20987602760803623,0.0,0.0,0.0008811142867625539,1
rnn,0.0032379613114201407,0.21067252107144432,0.0,0.0,0.0010167957879939258,1
optical coherence tomography,0.01137021355246156,0.23324457690052766,0.0,0.0,0.0006193817018740026,1
privacy,0.01137021355246156,0.23324457690052766,0.0,0.0,0.0011067030991514745,1
magnetic resonance imaging,0.011301634864636013,0.23251187142335322,0.0,0.0,0.0010530472484993401,1
robit regression,9.699033515735547e-11,0.04029334671797446,0.0,1.0,0.0012804586069737065,3
robust regression,9.699033515735547e-11,0.04029334671797446,0.0,1.0,0.0012804586069737065,3
sparsity,3.1188684131295716e-12,0.054026770358184394,0.0,0.0,0.001016524667042158,2
winbugs,3.1188684131295716e-12,0.054026770358184394,0.0,0.0,0.001271308792961477,2
markov chain monte carlo (mcmc),8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,18
space alternating data augmentation (sada),8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,18
posterior consistency,2.755037669262877e-12,0.04842168755445345,0.0,0.0,0.0005008542138408899,2
missing at random,3.5313883435488525e-12,0.046033768716151634,0.0,0.0,0.0011018255802779982,2
pca model building,2.055979702507223e-11,0.05545321974057871,0.0,0.0,0.0011916134387488003,2
probit regression,2.055979702507223e-11,0.05545321974057871,0.0,0.0,0.0012070709627872841,2
mixup,0.00295802316846914,0.2094800351031154,0.0,0.0,0.0009576105701954675,4
monotone splines,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,19
proportional odds model,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,19
natural language processing,0.0002118048158442921,0.16327120383036936,0.0,0.0,0.0011007813272359043,4
visual context,0.00569298053951281,0.21516360194699835,0.0,0.0,0.0007582034460617189,1
wafer map,0.004238249832163541,0.21087258994235736,0.0,0.0,0.0008833054481999605,1
plda,0.0007188891178898042,0.17608948232299945,0.0,0.0,0.0012832429194466809,1
speaker verification,0.011347179665100075,0.23299982918079995,0.0033392963625521765,0.0,0.0016773249928250073,1
poisson editing,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,20
pulmonary nodules,8.776828206510467e-26,0.002325581395348837,0.0,0.0,0.002320185614849188,20
recommender systems,0.0024901189997088135,0.2057913227148307,0.0,0.0,0.0015845466814515988,1
road extraction,0.0051624453579843495,0.2168445675872093,0.0,0.0,0.000602794395597639,1
rhetorical structure theory,0.0026840437097789627,0.20598222375631015,0.0,0.0,0.0011028172695618887,4
sequence-to-sequence speech recognition,0.0026707784694543885,0.2063650903432178,0.0,1.0,0.0016862640129367986,13
sequence-to-sequence speech synthesis,0.0026707784694543885,0.2063650903432178,0.0,1.0,0.0016862640129367984,13
speaker embedding,1.1282498431909705e-22,0.005232558139534884,2.168374261397517e-05,0.0,0.0021601672695045608,9
speaker recognition,1.1282498431909705e-22,0.005232558139534884,2.168374261397517e-05,0.0,0.003439571413519158,9
tdnn-lstm,6.972967508937589e-23,0.0034883720930232558,0.0,0.0,0.0012007998161792154,9
x-vectors,6.972967508937589e-23,0.0034883720930232558,0.0,0.0,0.0024802039601938136,9
speech synthesis,0.00295802316846914,0.2094800351031154,0.0,0.0,0.00118238963945965,4
vocal tract length perturbation,0.00022695359145497417,0.16351166215707094,0.0,0.0,0.0012230039844169202,4
